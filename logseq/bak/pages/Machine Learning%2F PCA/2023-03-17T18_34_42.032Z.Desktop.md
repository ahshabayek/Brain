- To reduce number of features
- ![image.png](../assets/image_1677616626877_0.png)
- ![image.png](../assets/image_1677616737377_0.png)
- ![image.png](../assets/image_1677616908309_0.png)
- how it works :
	- select a good feature to represent the data.
	- ![image.png](../assets/image_1677617046411_0.png)
	- ![image.png](../assets/image_1677617120048_0.png)
	- projection captures the data spread.
	- ![image.png](../assets/image_1677617162209_0.png)
	- worse data squished together.
	- ![image.png](../assets/image_1677617191114_0.png)
	- best cause it captures the most data variance.
	- How to project:
		- ![image.png](../assets/image_1677617490862_0.png)
		- selecting compenents:
		- ![image.png](../assets/image_1677617558983_0.png)
		- ![image.png](../assets/image_1677617625730_0.png)
		- there is no ground truth to measure up to, equidistant measuring between all features is made.
		- ![image.png](../assets/image_1677617700902_0.png)
		- best fit v.s feature reduction.
		- ![image.png](../assets/image_1677617802476_0.png)
-
- Implementation:
	- ![image.png](../assets/image_1677622212472_0.png)
	- ![image.png](../assets/image_1677622298985_0.png)
	- ![image.png](../assets/image_1677622369067_0.png)
- uses of PCA:
	- ![image.png](../assets/image_1677622478836_0.png)
	- for SVM helped.